{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataset,Useless_fatures, name_target = 'target', replace_Nan = 0):\n",
    "    dataset['ps_car_13_x_ps_reg_03'] = dataset['ps_car_13'] * dataset['ps_reg_03']\n",
    "    #transform float 64 -> 32\n",
    "    for c, dtype in zip(dataset.columns, dataset.dtypes): \n",
    "        if dtype == np.float64:     \n",
    "            dataset[c] = dataset[c].astype(np.float32)\n",
    "            \n",
    "    if replace_Nan != False:\n",
    "        dataset.replace(-1, replace_Nan )\n",
    "\n",
    "    if name_target in dataset:\n",
    "        X = dataset.drop([name_target],1)\n",
    "        X = X.drop(Useless_fatures,1)\n",
    "        \n",
    "        label = dataset[name_target]\n",
    "        y = label.as_matrix()\n",
    "        print(len(X), \" \",len(label))\n",
    "        return X , y\n",
    "    else:\n",
    "        return dataset.drop(Useless_fatures,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173552   173552\n",
      "3000   3000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "target_0 = train['target']==0\n",
    "target_1 = train['target']==1\n",
    "train_down_samp = train[target_1].append(train[target_0][0:int(sum(target_1)*4)])\n",
    "train_down_samp = train_down_samp.append(train[target_1])\n",
    "train_down_samp = train_down_samp.append(train[target_1])\n",
    "train_down_samp = train_down_samp.append(train[target_1])\n",
    "to_drop = ['ps_car_11_cat', 'ps_ind_14', 'ps_car_11', 'ps_car_14', 'ps_ind_06_bin', \n",
    "           'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', \n",
    "           'ps_ind_13_bin', 'id']\n",
    "\n",
    "X_50 , y_50 = prepare_data(train_down_samp,to_drop)\n",
    "y_50 = y_50.reshape([-1,1])\n",
    "\n",
    "X_real_test, y_real_test = prepare_data(shuffle(train)[0:3000],to_drop)\n",
    "y_real_test = y_real_test.reshape([-1,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_50 , y_50, test_size=0.02)\n",
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "N_FEATURES=X_train.shape[1]\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "# ### Placeholder variables\n",
    "x = tf.placeholder(tf.float32, [None, N_FEATURES],name=\"X-input\")\n",
    "y_true = tf.placeholder(tf.float32, [None,num_classes],name=\"y-input\") ##[None, num_classes]\n",
    "is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "# ### Helper-functions for creating new variables\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1), name = 'weight')\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]),name='bias')\n",
    "\n",
    "\n",
    "# ### Helper-function for creating a new Fully-Connected Layer\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True,  # Use Rectified Linear Unit (ReLU)?\n",
    "                 use_sig=False):\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif use_sig:\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "# ###  Layers\n",
    "#hyperparameters\n",
    "n_nodes_hl1 = 37\n",
    "n_nodes_hl2 = 35\n",
    "n_nodes_hl3 = 15\n",
    "\n",
    "beta = 0.002  # l2 regularization\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "norm = tf.contrib.layers.batch_norm(x, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn')\n",
    "layer_h1 = new_fc_layer(input=norm,\n",
    "                         num_inputs=input_size,\n",
    "                         num_outputs=n_nodes_hl1,\n",
    "                         use_relu=True)\n",
    "drop_h1 = tf.nn.dropout(layer_h1, 0.4 + keep_prob*0.6)\n",
    "\n",
    "layer_h2 = new_fc_layer(input=drop_h1,\n",
    "                         num_inputs=n_nodes_hl1,\n",
    "                         num_outputs=n_nodes_hl2,\n",
    "                         use_relu=False,\n",
    "                         use_sig = True)\n",
    "\n",
    "drop_h2 = tf.nn.dropout(layer_h2, 0.7 + keep_prob * 0.3)\n",
    "\n",
    "layer_h3 = new_fc_layer(input=layer_h2,\n",
    "                         num_inputs=n_nodes_hl2,\n",
    "                         num_outputs=n_nodes_hl3,\n",
    "                         use_relu=False,\n",
    "                         use_sig = True)\n",
    "\n",
    "drop_h3 = tf.nn.dropout(layer_h3, 0.5 + keep_prob * 0.5)\n",
    "\n",
    "y_pred = new_fc_layer(input=drop_h1,\n",
    "                         num_inputs=n_nodes_hl1,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False,\n",
    "                         use_sig = False)\n",
    "y_pred_soft_max = tf.nn.sigmoid(y_pred)\n",
    "#y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### Cost-function and Optimizer\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "#loss = tf.losses.mean_squared_error(y_true,y_pred_soft_max)\n",
    "#loss = tf.losses.sigmoid_cross_entropy(y_true,y_pred) #,weights= y_true*10\n",
    "loss = tf.square(y_pred_soft_max - y_true)/2\n",
    "\n",
    "var_s = tf.trainable_variables()\n",
    "loss_l2 = tf.add_n([tf.nn.l2_loss(v) for v in var_s if 'bias' not in v.name])*0.001\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "#error = tf.square(y_pred - y_true)/2 \n",
    "#cost = tf.reduce_sum(error + error* y_true*5)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)  #  1e-4\n",
    "\n",
    "# ### Performance measures\n",
    "correct_prediction = tf.equal(tf.round(y_pred_soft_max), y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 42.4%\n",
      "0.11042450689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "#feed_dict_test = {x: X_test, y_true: y_test, keep_prob: 1.0}  #.values.reshape([-1,1])\n",
    "feed_dict_real_test = {x: X_real_test, y_true:y_real_test, keep_prob: 1.0,is_train:False}\n",
    "####\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def gini(y_actual, y_pred):\n",
    "    return 2*roc_auc_score(y_actual, y_pred)-1\n",
    "####\n",
    "def print_accuracy( r_valu = False, feed = feed_dict_real_test):\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed)\n",
    "    #print(precision_score(y_real_test,pred))\n",
    "    if r_valu:\n",
    "        return acc\n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))\n",
    "\n",
    "print_accuracy()\n",
    "from eval import normalized_gini\n",
    "def print_gini():\n",
    "    y_p,y = session.run([y_pred_soft_max,y_true], feed_dict=feed_dict_real_test)\n",
    "    #print(y[:,1])\n",
    "    return gini(y,y_p)\n",
    "print(print_gini())\n",
    "    \n",
    "saver = tf.train.Saver()  #search tf.saver.tensorflow\n",
    "best_validation_accuracy = 0\n",
    "best_validation_gini = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "def optimize( hm_epochs = 15, learning_r = 1e-4):\n",
    "    global best_validation_accuracy,best_validation_gini\n",
    "    global global_step\n",
    "    for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            i = 0\n",
    "            len_train = X_train.shape[0]\n",
    "            while i < len_train:\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "\n",
    "                batch_x = np.array(X_train[start:end])\n",
    "                batch_y = np.array(y_train[start:end])    #.values.reshape([-1,1]))\n",
    "                \n",
    "                feed_dict_train = {x: batch_x,\n",
    "                                   y_true: batch_y,\n",
    "                                   keep_prob: 0.0,is_train:True}\n",
    "                \n",
    "                _, c = session.run([optimizer,cost], feed_dict=feed_dict_train)\n",
    "                epoch_loss += c\n",
    "\n",
    "                \n",
    "\n",
    "                if i % 50000 == 0  or i == (len_train - 1) or i == 0:\n",
    "                    \n",
    "\n",
    "                    acc_ = print_accuracy(True)\n",
    "                    if acc_ > best_validation_accuracy:\n",
    "                        best_validation_accuracy = acc_\n",
    "                        saver.save(session, 'models/my_model_acc')\n",
    "                        imp_str_acc = '*'*4\n",
    "                    else:\n",
    "                        imp_str_acc = ''\n",
    "                    gini = print_gini()\n",
    "                    if gini > best_validation_gini:\n",
    "                        best_validation_gini = gini\n",
    "                        saver.save(session, 'models/my_model_gini')\n",
    "                        imp_str_gini = '*'*4\n",
    "                    else:\n",
    "                        imp_str_gini = ''\n",
    "\n",
    "                    print('epoch:{} loss: {:.4f},  acc: {:.4f}{} __gini: {:.4f}{}'.format(epoch,epoch_loss,acc_*100,imp_str_acc,gini,imp_str_gini))\n",
    "                    epoch_loss = 0\n",
    "                i += batch_size\n",
    "\n",
    "\n",
    "    print('Epoch {} completed out of {}'.format(epoch+1,hm_epochs))\n",
    "\n",
    "    print('Optimization ended '+ 10*'_' + 'best accuracy: {}'.format(best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255055571012\n",
      "0.242839466401\n",
      "Accuracy on test-set: 64.7%\n"
     ]
    }
   ],
   "source": [
    "print(best_validation_gini)\n",
    "print(print_gini())\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss: 0.1178,  acc: 64.5667 __gini: 0.2429\n",
      "epoch:1 loss: 0.1176,  acc: 64.7667 __gini: 0.2458\n",
      "epoch:2 loss: 0.1156,  acc: 63.9000 __gini: 0.2437\n",
      "epoch:3 loss: 0.1176,  acc: 64.3333 __gini: 0.2427\n",
      "epoch:4 loss: 0.1159,  acc: 64.1000 __gini: 0.2417\n",
      "epoch:5 loss: 0.1171,  acc: 63.9667 __gini: 0.2406\n",
      "epoch:6 loss: 0.1178,  acc: 63.6000 __gini: 0.2400\n",
      "epoch:7 loss: 0.1168,  acc: 63.7000 __gini: 0.2418\n",
      "epoch:8 loss: 0.1173,  acc: 63.9000 __gini: 0.2455\n",
      "epoch:9 loss: 0.1162,  acc: 63.9667 __gini: 0.2440\n",
      "epoch:10 loss: 0.1171,  acc: 63.8333 __gini: 0.2433\n",
      "epoch:11 loss: 0.1165,  acc: 64.1333 __gini: 0.2403\n",
      "epoch:12 loss: 0.1166,  acc: 63.8000 __gini: 0.2404\n",
      "epoch:13 loss: 0.1173,  acc: 63.8333 __gini: 0.2421\n",
      "epoch:14 loss: 0.1173,  acc: 63.7667 __gini: 0.2413\n",
      "epoch:15 loss: 0.1168,  acc: 63.7333 __gini: 0.2404\n",
      "epoch:16 loss: 0.1163,  acc: 63.8667 __gini: 0.2379\n",
      "epoch:17 loss: 0.1158,  acc: 64.3000 __gini: 0.2406\n",
      "epoch:18 loss: 0.1166,  acc: 63.6667 __gini: 0.2427\n",
      "epoch:19 loss: 0.1172,  acc: 63.9333 __gini: 0.2432\n",
      "epoch:20 loss: 0.1170,  acc: 63.2667 __gini: 0.2406\n",
      "epoch:21 loss: 0.1162,  acc: 63.3333 __gini: 0.2404\n",
      "epoch:22 loss: 0.1165,  acc: 63.9667 __gini: 0.2419\n",
      "epoch:23 loss: 0.1174,  acc: 63.6000 __gini: 0.2435\n",
      "epoch:24 loss: 0.1165,  acc: 64.5333 __gini: 0.2390\n",
      "epoch:25 loss: 0.1166,  acc: 64.3333 __gini: 0.2376\n",
      "epoch:26 loss: 0.1165,  acc: 64.1667 __gini: 0.2386\n",
      "epoch:27 loss: 0.1172,  acc: 64.2000 __gini: 0.2383\n",
      "epoch:28 loss: 0.1165,  acc: 63.8667 __gini: 0.2375\n",
      "epoch:29 loss: 0.1166,  acc: 63.6667 __gini: 0.2420\n",
      "epoch:30 loss: 0.1178,  acc: 64.2333 __gini: 0.2354\n",
      "epoch:31 loss: 0.1167,  acc: 64.0333 __gini: 0.2337\n",
      "epoch:32 loss: 0.1158,  acc: 63.9333 __gini: 0.2346\n",
      "epoch:33 loss: 0.1176,  acc: 64.1000 __gini: 0.2382\n",
      "epoch:34 loss: 0.1169,  acc: 63.7667 __gini: 0.2374\n",
      "epoch:35 loss: 0.1176,  acc: 64.3333 __gini: 0.2392\n",
      "epoch:36 loss: 0.1179,  acc: 63.4667 __gini: 0.2431\n",
      "epoch:37 loss: 0.1167,  acc: 64.0667 __gini: 0.2413\n",
      "epoch:38 loss: 0.1167,  acc: 63.9000 __gini: 0.2402\n",
      "epoch:39 loss: 0.1161,  acc: 64.4667 __gini: 0.2413\n",
      "epoch:40 loss: 0.1171,  acc: 63.7667 __gini: 0.2410\n",
      "epoch:41 loss: 0.1166,  acc: 63.1333 __gini: 0.2385\n",
      "epoch:42 loss: 0.1174,  acc: 64.0000 __gini: 0.2395\n",
      "epoch:43 loss: 0.1169,  acc: 64.1333 __gini: 0.2400\n",
      "epoch:44 loss: 0.1165,  acc: 63.5333 __gini: 0.2404\n",
      "epoch:45 loss: 0.1170,  acc: 63.8000 __gini: 0.2384\n",
      "epoch:46 loss: 0.1179,  acc: 63.8000 __gini: 0.2392\n",
      "epoch:47 loss: 0.1156,  acc: 63.7333 __gini: 0.2363\n",
      "epoch:48 loss: 0.1170,  acc: 64.0333 __gini: 0.2352\n",
      "epoch:49 loss: 0.1165,  acc: 64.3667 __gini: 0.2357\n",
      "epoch:50 loss: 0.1170,  acc: 63.6667 __gini: 0.2397\n",
      "epoch:51 loss: 0.1172,  acc: 63.3667 __gini: 0.2403\n",
      "epoch:52 loss: 0.1170,  acc: 63.8000 __gini: 0.2406\n",
      "epoch:53 loss: 0.1163,  acc: 63.7333 __gini: 0.2371\n",
      "epoch:54 loss: 0.1168,  acc: 63.8000 __gini: 0.2364\n",
      "epoch:55 loss: 0.1166,  acc: 63.7333 __gini: 0.2363\n",
      "epoch:56 loss: 0.1174,  acc: 63.8667 __gini: 0.2408\n",
      "epoch:57 loss: 0.1162,  acc: 64.1000 __gini: 0.2387\n",
      "epoch:58 loss: 0.1180,  acc: 64.1667 __gini: 0.2343\n",
      "epoch:59 loss: 0.1171,  acc: 63.9000 __gini: 0.2368\n",
      "epoch:60 loss: 0.1170,  acc: 63.7000 __gini: 0.2374\n",
      "epoch:61 loss: 0.1162,  acc: 63.5333 __gini: 0.2383\n",
      "epoch:62 loss: 0.1169,  acc: 63.6333 __gini: 0.2386\n",
      "epoch:63 loss: 0.1159,  acc: 63.9000 __gini: 0.2390\n",
      "epoch:64 loss: 0.1168,  acc: 63.5667 __gini: 0.2426\n",
      "epoch:65 loss: 0.1170,  acc: 63.7667 __gini: 0.2411\n",
      "epoch:66 loss: 0.1170,  acc: 63.7667 __gini: 0.2389\n",
      "epoch:67 loss: 0.1166,  acc: 64.1667 __gini: 0.2432\n",
      "epoch:68 loss: 0.1164,  acc: 63.3000 __gini: 0.2396\n",
      "epoch:69 loss: 0.1178,  acc: 64.0667 __gini: 0.2416\n",
      "epoch:70 loss: 0.1166,  acc: 63.8000 __gini: 0.2439\n",
      "epoch:71 loss: 0.1171,  acc: 64.0333 __gini: 0.2443\n",
      "epoch:72 loss: 0.1167,  acc: 64.3000 __gini: 0.2440\n",
      "epoch:73 loss: 0.1171,  acc: 64.4667 __gini: 0.2443\n",
      "epoch:74 loss: 0.1168,  acc: 63.9667 __gini: 0.2417\n",
      "epoch:75 loss: 0.1176,  acc: 63.4000 __gini: 0.2393\n",
      "epoch:76 loss: 0.1167,  acc: 63.9667 __gini: 0.2410\n",
      "epoch:77 loss: 0.1174,  acc: 64.6000 __gini: 0.2389\n",
      "epoch:78 loss: 0.1171,  acc: 64.0667 __gini: 0.2377\n",
      "epoch:79 loss: 0.1160,  acc: 63.5667 __gini: 0.2422\n",
      "epoch:80 loss: 0.1176,  acc: 64.4333 __gini: 0.2411\n",
      "epoch:81 loss: 0.1171,  acc: 64.4333 __gini: 0.2382\n",
      "epoch:82 loss: 0.1170,  acc: 63.5000 __gini: 0.2379\n",
      "epoch:83 loss: 0.1169,  acc: 63.9333 __gini: 0.2373\n",
      "epoch:84 loss: 0.1166,  acc: 63.8667 __gini: 0.2417\n",
      "epoch:85 loss: 0.1164,  acc: 63.6000 __gini: 0.2416\n",
      "epoch:86 loss: 0.1174,  acc: 63.3333 __gini: 0.2396\n",
      "epoch:87 loss: 0.1167,  acc: 64.4667 __gini: 0.2383\n",
      "epoch:88 loss: 0.1163,  acc: 64.1333 __gini: 0.2324\n",
      "epoch:89 loss: 0.1172,  acc: 64.2667 __gini: 0.2387\n",
      "epoch:90 loss: 0.1162,  acc: 63.9667 __gini: 0.2375\n",
      "epoch:91 loss: 0.1171,  acc: 64.2000 __gini: 0.2349\n",
      "epoch:92 loss: 0.1176,  acc: 64.3333 __gini: 0.2388\n",
      "epoch:93 loss: 0.1169,  acc: 64.0333 __gini: 0.2381\n",
      "epoch:94 loss: 0.1175,  acc: 64.0333 __gini: 0.2345\n",
      "epoch:95 loss: 0.1171,  acc: 63.2000 __gini: 0.2387\n",
      "epoch:96 loss: 0.1179,  acc: 63.8667 __gini: 0.2404\n",
      "epoch:97 loss: 0.1175,  acc: 63.3000 __gini: 0.2373\n",
      "epoch:98 loss: 0.1172,  acc: 63.1667 __gini: 0.2398\n",
      "epoch:99 loss: 0.1165,  acc: 63.8333 __gini: 0.2384\n",
      "epoch:100 loss: 0.1171,  acc: 64.0000 __gini: 0.2436\n",
      "epoch:101 loss: 0.1163,  acc: 64.1333 __gini: 0.2395\n",
      "epoch:102 loss: 0.1175,  acc: 63.7333 __gini: 0.2369\n",
      "epoch:103 loss: 0.1170,  acc: 64.0333 __gini: 0.2388\n",
      "epoch:104 loss: 0.1175,  acc: 64.7667 __gini: 0.2396\n",
      "epoch:105 loss: 0.1189,  acc: 64.2000 __gini: 0.2424\n",
      "epoch:106 loss: 0.1186,  acc: 63.9667 __gini: 0.2429\n",
      "epoch:107 loss: 0.1175,  acc: 64.1000 __gini: 0.2429\n",
      "epoch:108 loss: 0.1169,  acc: 64.2000 __gini: 0.2422\n",
      "epoch:109 loss: 0.1165,  acc: 63.9333 __gini: 0.2403\n",
      "epoch:110 loss: 0.1169,  acc: 64.2333 __gini: 0.2401\n",
      "epoch:111 loss: 0.1175,  acc: 63.4333 __gini: 0.2397\n",
      "epoch:112 loss: 0.1162,  acc: 63.2000 __gini: 0.2418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-12ddb9c61888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-6d8596123612>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(hm_epochs, learning_r)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                    keep_prob: 0.0,is_train:True}\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40503132],\n",
       "       [ 0.37383202],\n",
       "       [ 0.52046144],\n",
       "       [ 0.495628  ],\n",
       "       [ 0.36780107],\n",
       "       [ 0.60976785],\n",
       "       [ 0.31874985],\n",
       "       [ 0.4654856 ],\n",
       "       [ 0.23325017],\n",
       "       [ 0.45791605],\n",
       "       [ 0.43127698],\n",
       "       [ 0.27411601],\n",
       "       [ 0.56887966],\n",
       "       [ 0.43301222],\n",
       "       [ 0.53742951],\n",
       "       [ 0.4060739 ],\n",
       "       [ 0.42917451],\n",
       "       [ 0.50185746],\n",
       "       [ 0.3814179 ],\n",
       "       [ 0.28370029]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(y_pred_soft_max,feed_dict_real_test)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loaded\n",
      "INFO:tensorflow:Restoring parameters from models/my_model_acc\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print('test loaded')\n",
    "\n",
    "#X_sub = transform_df(test)\n",
    "X_sub = prepare_data(test,to_drop)\n",
    "saver.restore(session,\"models/my_model_acc\")\n",
    "sub1 = session.run(y_pred_soft_max,feed_dict={x:X_sub[:int(892816/2)],keep_prob:1.0,is_train:False})\n",
    "sub2 = session.run(y_pred_soft_max,feed_dict={x:X_sub[int(892816/2):],keep_prob:1.0,is_train:False})\n",
    "sub_tot_A = np.append(sub1,sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/my_model_gini\n"
     ]
    }
   ],
   "source": [
    "saver.restore(session,\"models/my_model_gini\")\n",
    "sub1 = session.run(y_pred_soft_max,feed_dict={x:X_sub[:int(892816/2)],keep_prob:1.0,is_train:False})\n",
    "sub2 = session.run(y_pred_soft_max,feed_dict={x:X_sub[int(892816/2):],keep_prob:1.0,is_train:False})\n",
    "sub_tot_B = np.append(sub1,sub2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = test.id.values\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = (sub_tot_B + sub_tot_B)/2\n",
    "\n",
    "#series = pd.Series(sub_tot)\n",
    "sub.to_csv('sub/submisssdsion_gini_{}.csv'.format(int(best_validation_accuracy*100)) ,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
